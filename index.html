<html xmlns="https://xiaoqin-wang.github.io" xml:lang="en">
  
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Xiaoqin Wang</title>
</head>
  
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Xiaoqin Wang</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="biography.html">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Xiaoqin Wang</h1>
</div>
<table class="imgtable"><tr><td>
<img src="xiaoqin.jpg" alt="xiaoqin" width="175px" height="230px" />&nbsp;</td>
<td align="left"><p>Xiaoqin Wang&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="http://www.njust.edu.cn/"><img src="NUST.jpg" alt=“NUST” width="130px" height="130px" /></a><br />
<b>Researcher</b><br />
Guilin University of Electronic Technology<br /></p>
Email: xqwang@guet.edu.cn<br /></p>
</td></tr></table>
  
<h2>About Me</h2>
<ul>
<li><p>From Jun. 2020, I am a Professor at PCA Lab (led by Prof. <a href="http://202.119.85.163/open/TutorInfo.aspx?dsbh=tLbjVM9T1OzsoNduSpyHQg==&amp;yxsh=4iVdgPyuKTE=&amp;zydm=L-3Jh59wXco=">Jian Yang</a>) and Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, School of Computer Science and Engineering, <a href="http://www.njust.edu.cn/">NJUST</a>.</p>
</li>
</ul>
<h2>Updates</h2>
  
<ul>
<li><p>Dec. 2, 2020: One paper about long-tailed recognition accepted by <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.</p>
</li>
<li><p>Sept. 25, 2020: One paper about base models accepted by IEEE TNNLS.

</p>
</li>
<li><p>Aug. 1, 2020: Two papers accepted to <a href="https://2020.acmmm.org/index.html">ACM MM 2020</a>: one for webly-supervised fine-grained recognition and one for retrieval toolbox.
</p>
</li>
<li><p>Jul. 3, 2020: Two papers accepted to <a href="https://eccv2020.eu/">ECCV 2020</a>: one for fine-grained image retrieval and one for object detection.
</p>
</li>
<li><p>Jun. 20, 2020: Our team won the <b>first place</b> in the <a href="https://www.kaggle.com/c/iwildcam-2020-fgvc7/leaderboard">iWildCam</a> track of FGVC 2020 global competitions!

</p>
</li>
<li><p>Apr. 28, 2020: We release a PyTorch-based library for unsupervised image retrieval by deep CNNs on <a href="https://github.com/PyRetri/PyRetri">GitHub</a>!</p>
</li>
<li><p>Apr. 21, 2020: <b>Our work (<a href="publication/tip17SCDA.pdf">SCDA</a>) about fine-grained image retrieval was selected as the highly cited paper by ESI!</b>



</p>
</li>
<li><p>Jul. 6, 2019: Opened the &ldquo;<a href="http://www.weixiushen.com/project/Awesome_FGIA/Awesome_FGIA.html">Awesome Fine-Grained Image Analysis – Papers, Codes and Datasets</a>&rdquo; homepage.
</p>
</li>
<li><p>Jun. 12, 2019: Our team won the <b>first place</b> in <b>both <a href="https://www.kaggle.com/c/inaturalist-2019-fgvc6/leaderboard">iNaturalist</a> and <a href="https://www.kaggle.com/c/herbarium-2019-fgvc6/leaderboard">Herbarium</a> tracks</b> of FGVC 2019 global competition!



</p>
</li>
<li><p>Nov. 1, 2018: <b>Published <a href="https://detail.tmall.com/item.htm?spm=a230r.1.14.13.443951e1EzWpSc&amp;id=581180454111&amp;ns=1&amp;abbucket=6">a Chinese book on convolutional neural networks and computer vision</a></b>.



































</p>
</li>
</ul>
<h2>Research Interests</h2>
<p>My research interests include some sub-fields of <b>Computer Vision</b> and <b>Machine Learning</b>:</p>
<ul>
<li><p><b>Deep Convolutional Neural Networks</b> (DCNN) is a type of feed-forward artificial neural network where the individual neurons are tiled in such a way that they respond to overlapping regions in the visual field, which is widely used in image and video related tasks.</p>
</li>
</ul>
<ul>
<li><p><b>Fine-Grained Image Analysis</b> (FGIA) is a hot topic in computer vision and pattern recognition. The goals of FGIA are localizing the fine-grained objects, recognizing the objects&rsquo; subordinate categories, retrieving the fine-grained objects and so on.</p>
</li>
</ul>
<ul>
<li><p><b>Long-Tailed Distribution Learning</b> (LTDL) deals with real-world datasets displaying skewed distributions with <i>a long tail</i>, i.e., a few classes (a.k.a. head classes) occupy most of the data, while most classes (a.k.a. tail classes) have rarely few samples.</p>
</li>
</ul>
<ul>
<li><p><b>General Object Detection</b> is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class in digital images and videos.</p>
</li>
</ul>
<ul>
<li><p><b>Weakly Supervised Learning</b> (WSL), especially Multi-Instance Learning (MIL), is a variation on supervised learning. Instead of receiving a set of instances which are individually labeled, the learner receives a set of labeled <i>bags</i>, each containing many instances.</p>
</li>
</ul>
<ul>
<li><p><b>Bag-of-Words Model</b> (BoW) can be applied to image related tasks by encoding local visual descriptors of one image into a high dimensional vector. In BoW, there also include <i>Vector of the Locally Aggregated Descriptors</i> (<i>VLAD</i>) and <i>Fisher Vector</i> (<i>FV</i>).</p>
</li>
</ul>
<h2>Selected Publications</h2>
<p><tt>My papers are available for download in this <a href="./papers.html">Publications</a> page, and here is my  <a href="https://scholar.google.com/citations?user=Qzyy5mcAAAAJ&amp;hl=en">Google Scholar Citations profile</a>.</tt>
<br /><br /></p>
<ul>
<li><p><a href="publication/tip17SCDA.pdf">Selective Convolutional Descriptor Aggregation for Fine-Grained Image Retrieval</a>.
<br /><p style="color:red"><i>(This work was the highly cited paper by ESI, which received enough citations to place it in the top 1% of its academic field.)</i></p>
<b>X.-S. Wei</b>, J.-H. Luo, J. Wu, and Z.-H. Zhou.
<br /><i>IEEE Transactions on Image Processing (TIP)</i>, 2017, 26(6): 2868-2881.</p>
</li>
</ul>
<ul>
<li><p><a href="publication/cvpr20_BBN.pdf">BBN: Bilateral-Branch Network with Cumulative Learning for Long-Tailed Visual Recognition</a>. (<b><i>Oral presentation</i></b>)
<br /><p style="color:red"><i>(This work was the winner solution of the iNaturalist 2019 global competition.)</i></p>

B. Zhou, Q. Cui, <b>X.-S. Wei*</b>, and Z.-M. Chen.
<br /><i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR’20)</i>, Virtual Conference, 2020, pp. 9719-9728.</p>
</li>
</ul>
<ul>
<li><p><a href="publication/tip19PCM.pdf">Piecewise Classifier Mappings: Learning Fine-Grained Learners for Novel Categories with Few Examples</a>.
<br /><b>X.-S. Wei</b>, P. Wang, L. Liu, C. Shen, and J. Wu.
<br /><i>IEEE Transactions on Image Processing (TIP)</i>, 2019, 28(12): 6116-6125.</p>
</li>
</ul>
<ul>
<li><p><a href="publication/tkde19.pdf">Multiple Instance Learning with Emerging Novel Class</a>.
<br /><b>X.-S. Wei</b>, H.-J. Ye, X. Mu, J. Wu, C. Shen, and Z.-H. Zhou.
<br /><i>IEEE Transactions on Knowledge and Data Engineering (TKDE)</i>, 2019, in press.</p>
</li>
</ul>
<ul>
<li><p><a href="publication/eccv20_ExchNet.pdf">ExchNet: A Unified Hashing Network for Large-Scale Fine-Grained Image Retrieval</a>.
<br />Q. Cui, Q.-Y. Jiang, <b>X.-S. Wei*</b>, W.-J. Li, and O. Yoshie. (<b><i>Oral presentation</i></b>)
<br /><i>European Conference on Computer Vision (ECCV’20)</i>, Virtual Conference, 2020, pp. xx-xx.</p>
</li>
</ul>
<ul>
<li><p><a href="publication/mlj16.pdf">An Empirical Study on Image Bag Generators for Multi-Instance Learning</a>.
<br /><b>X.-S. Wei</b>, and Z.-H. Zhou.
<br /><i>Machine Learning</i>, 2016, 105(2): 155-198.</p>
</li>
</ul>
<ul>
<li><p><a href="publication/pr17.pdf">Mask-CNN: Localizing Parts and Selecting Descriptors for Fine-Grained Bird Species Categorization</a>.
<br /><b>X.-S. Wei</b>, C.-W. Xie, J. Wu, and C. Shen.
<br /><i>Pattern Recognition</i>, 2018, 76:704-714.</p>
</li>
</ul>
<ul>
<li><p><a href="publication/ijcai17.pdf">Deep Descriptor Transforming for Image Co-Localization</a>.
<br /><b>X.-S. Wei</b>, C.-L. Zhang, Y. Li, C.-W. Xie, J. Wu, C. Shen, and Z.-H. Zhou. 
<br /><i>International Joint Conference on Artificial Intelligence (IJCAI’17)</i>, Melbourne, Australia, 2017, pp. 3048-3054.</p>
</li>
</ul>
<h2>Professional Activities (Selected)</h2>
<h3>Young Scientists Committee</h3>
<ul>
<li><p>Journal of Image and Graphics (中国图象图形学报), Dec. 2020 -</p>
</li>
</ul>
<h3>Program Chair / Co-Chair</h3>
<ul>
<li><p>Asian Conference on Computer Vision (ACCV) Workshop on <a href="https://sites.google.com/view/webfg2020">Webly-Supervised Fine-Grained Recognition</a>, 2020</p>
</li>
</ul>
<h3>Publicity Chair</h3>
<ul>
<li><p>PRCV <a href="http://www.prcv.cn/committees_en.html">2020</a></p>
</li>
</ul>
<h3>Area Chair / Senior PC</h3>
<ul>
<li><p>IJCAI <a href="https://ijcai-21.org/">2021</a></p>
</li>
</ul>
<h3>Program Committee Member</h3>
<ul>
<li><p>CVPR <a href="http://cvpr2017.thecvf.com/">2017</a>, <a href="http://cvpr2018.thecvf.com/">2018</a>, <a href="http://cvpr2019.thecvf.com/">2019</a>, <a href="http://cvpr2020.thecvf.com/">2020</a>, <a href="http://cvpr2021.thecvf.com/">2021</a></p>
</li>
<li><p>ICCV <a href="http://iccv2017.thecvf.com/">2017</a>,  <a href="http://iccv2019.thecvf.com/">2019</a></p>
</li>
<li><p>ECCV <a href="https://eccv2018.org/">2018</a></p>
</li>
<li><p>NeurIPS <a href="https://nips.cc/Conferences/2016/">2016</a>, <a href="https://nips.cc/Conferences/2018/">2018</a>, <a href="https://neurips.cc/Conferences/2020">2020</a></p>
</li>
<li><p>IJCAI <a href="https://www.ijcai-18.org/">2018</a>, <a href="https://ijcai19.org/">2019</a>,  <a href="https://www.ijcai20.org/">2020</a></p>
</li>
<li><p>AAAI <a href="https://www.aaai.org/Conferences/AAAI/aaai16.php">2016</a>, <a href="https://www.aaai.org/Conferences/AAAI/aaai17.php">2017</a>, <a href="https://aaai.org/Conferences/AAAI-18/">2018</a>, <a href="https://aaai.org/Conferences/AAAI-19/">2019</a>, <a href="https://aaai.org/Conferences/AAAI-20/">2020</a>, <a href="https://aaai.org/Conferences/AAAI-21/">2021</a></p>
</li>
<li><p>ICLR <a href="https://iclr.cc/Conferences/2021">2021</a></p>
</li>
<li><p>ACCV <a href="http://accv2018.net/">2018</a>, <a href="http://accv2020.kyoto/">2020</a></p>
</li>
<li><p>BMVC <a href="https://bmvc2019.org/">2019</a>, <a href="https://bmvc2020.github.io/">2020</a></p>
</li>
<li><p>WACV <a href="http://wacv2021.thecvf.com/">2021</a></p>
</li>
<li><p>PRCV <a href="http://www.prcv2019.com/#/">2019</a>, <a href="http://prcv.cn/2020/index_en.html">2020</a></p>
</li>
<li><p>…
</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
